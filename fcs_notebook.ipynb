{
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "name": "",
  "signature": "sha256:bff76964eeb70a5ec9c34928bf118be15ff7d5fe82ece4b4d59048b096e6e558"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Virtual FCS, using MD Simulation Data\n",
      "\n",
      "This goal of this notebook is to generate a simulated FCS measurement using data from a GROMACS simulation.\n",
      "\n",
      "The setup of the virtual system is a membrane with a circularly symmetric incident beam.\n",
      "\n",
      "Data is read in from an .xtc or .trr file, using a .gro file to define the system topology. Data frames from the input file are iterated through, and for each frame, a detected intensity from each lipid is calculated. The intensity trace and autocorrelation functions for each lipid, and for the total at each frame, are plotted."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## TODOs\n",
      "\n",
      "#### \u2612 Why don't autocorrelation curves look right? Flatness in middle is unexpected\n",
      "- Done. See below\n",
      " \n",
      "#### \u2612 Generate and plot autocorrelation curve prediction. I'm still not understanding something about autocorrelation curves - I don't see where the sigmoid shape comes from.\n",
      " - Done. Curves need to be plotted on a semilog scale in order to see the expected sigmoid shape.\n",
      " \n",
      "#### \u2612 Try autocorrelating the data myself instead of using acorr. Maybe something weird is happening with the way matplotlib does autocorrelation that isn't desirable.\n",
      " - Done. The manually autocorrelated data is identical to calling plt.acorr with normed=True\n",
      " \n",
      "#### \u2612 Parallelize data analysis\n",
      " - Tried it. The analysis is quite computationally cheap compared to the extra overhead from spawning new threads -- not worth the time saved by running the analysis in parallel.\n",
      " \n",
      "#### \u2612 Handle breaking data up into bins better -- currently ignores the remainder of lipids that don't fall into a bin. (I.e. 11 lipids, bin size 3, the remaining 2 that don't evenly fall into bins are discarded.)\n",
      " - Done. The leftover lipids are put into their own bin, which may be smaller than the BIN_SIZE.\n",
      "     \n",
      "#### \u2610 Come up with a meaningful way of plotting uncertainties.\n",
      " - The way I have it defined now, $\\delta I(t) = I(t) - \\langle I(t) \\rangle$ isn't a particularly meaningful quantity. Since $\\langle I(t) \\rangle = \\frac{I(t)}{\\text{BIN_SIZE}}$ at a time step $t$, all these quantities are just scalar multiples of each other.\n",
      "     \n",
      "[Checkbox symbols]:<> (\u2612 \u2610)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Notes on input data\n",
      "\n",
      "It's recommended to 'unwrap' simulation data to remove potential artifacts from periodic boundary conditions in the simulation.\n",
      "\n",
      "### Method 1 (Better for big systems)\n",
      "The *best* way of doing this requires a trajectory file (i.e. `.xtc`, `.trr`), a `.gro`, and a `.tpr`. By doing this, the input data filesizes can be significantly reduced off the bat by selecting only the lipid groups to keep in the new trajectory file. This can be accomplished by running the following.\n",
      "\n",
      "When prompted to select a group, select only the group of lipids.\n",
      "\n",
      "`$>gmx trjconv -f <trajectory file> -s <.gro file> -o <output trajectory file> -pbc nojump`\n",
      "\n",
      "`$>gmx trjconv -f <.gro file> -s <.tpr file> -o <output .gro file> -pbc nojump`\n",
      "\n",
      "### Method 2\n",
      "This can also be done in one step, with only a trajectory file and a `.gro` file by selecting the group of ALL atoms when prompted.\n",
      "\n",
      "`$>gmx trjconv -f <trajectory file> -s <.gro file> -o <output trajectory file> -pbc nojump`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "trajectory_file = \"40nm/run.xtc\"\n",
      "trr_file = \"40nm/run.trr\"\n",
      "topology_file = \"40nm/system.gro\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import mdtraj as md\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import multiprocessing\n",
      "\n",
      "plt.rcParams['figure.figsize'] = (20, 12)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Simulation constants"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Detection area parameters\n",
      "\n",
      "`spot_radius` is used to determine whether a particle is within the detection area. Currently, this is unused, as cutoff is determined by the sigma of the beam Gaussian."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# Radius of detection area (in nanometers)\n",
      "spot_radius = 10 # Currently unused\n",
      "\n",
      "# Coordinates of detection area center (in nanometers)\n",
      "spotX = 0.0\n",
      "spotY = 0.0\n",
      "spotZ = 10.0 # This isn't used, since we're looking at 2D membranes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Gaussian parameters"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "#   Radial and axial std. dev.s of the Gaussian beam profile\n",
      "w_xy = 5\n",
      "w_z = 2 # Unused\n",
      "k = w_z/w_xy # Unused, just considering a 2-D membrane"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Various simulation parameters\n",
      "\n",
      "`STEP` is the stride used when iterating through data frames. Data frames are taken every timestep.\n",
      "\n",
      "`INTENSITY` is a scaling constant used to determine the maximum intensity of fluorescence.\n",
      "\n",
      "`SAMPLING_RATIO` defines the percentage of particles to be 'tagged'. Untagged particles are discarded at the beginning of the simulation.\n",
      "\n",
      "`CUTOFF` defines a cutoff for the beam profile. This may be useful to avoid artifacts from periodic boundary conditions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# Step size for iterating through data frames\n",
      "STEP = 1\n",
      "\n",
      "# Scaling constant for the intensity of a fluorescing particle\n",
      "INTENSITY = 1\n",
      "\n",
      "# Percentage of tagged particles\n",
      "SAMPLING_RATIO = .1\n",
      "\n",
      "# How many sigmas out from the beam center to truncate the beam's Gaussian profile at\n",
      "CUTOFF = 3\n",
      "\n",
      "# How many lipids to bin into a single trajectory\n",
      "BIN_SIZE = 100"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Diffusion parameters\n",
      "\n",
      "`D` is the diffusion constant for POPC, ~~using data from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1303347/~~ using values from Andrew's STRD paper, in units of nm^2/ns.\n",
      "\n",
      "`tauD` is the expected diffusion time, or the time of the half-max for the autocorrelation curve."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#D = .01 From NIH paper\n",
      "D = .0245\n",
      "tauD = w_xy**2 / (4*D)\n",
      "print(\"Expected diffusion time is %.2f nanoseconds\" % tauD)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Expected diffusion times for various beam waists"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "beam_waists = np.linspace(10,100,10) # In nanometers\n",
      "print(\"beam waist (nm)\".ljust(16) + \"|\" + \"tau_D (ns)\".rjust(15))\n",
      "print(\"-\"*27)\n",
      "for v in beam_waists:\n",
      "    print(str(v).ljust(16) + \"|\" + str(v ** 2 / (4*D)).rjust(15) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Useful functions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### `check_in_detection_volume`\n",
      "Function to check if a given lipid is within the detection volume.\n",
      "\n",
      "Right now, we're interested in contributions from all lipids regardless of position, so the `return True` short circuits it. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def check_in_detection_volume(t, frame_index, residue):\n",
      "\n",
      "    # For now, pay attention to all atoms, regardless of whether or not they're\n",
      "    #   in the detection volume. \n",
      "    # Keep this function as a placeholder, in case this changes.\n",
      "    return True\n",
      "\n",
      "    x, y, z = t.xyz[frame_index, residue._atoms[0].index]\n",
      "\n",
      "    # Get magnitude of distance to the spot center\n",
      "    distance = (x - spotX)**2 + (y - spotY)**2\n",
      "\n",
      "    # Check if the distance is within the spot radius\n",
      "    in_detection_area = distance <= spot_radius**2\n",
      "\n",
      "    return in_detection_area"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### `generate_detection`\n",
      "Defines what happens when a detection is generated from a lipid. Right now, `INTENSITY` is weighted by a 2-D Gaussian determined by the cell's position.\n",
      "\n",
      "$I = I_0 \\exp{ \\left( - \\frac{(x-x_0)^2 + (y-y_0)^2 }{2 \\sigma^2} \\right) }$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def generate_detection(t, frame_index, atom):\n",
      "\n",
      "    # Get coordinates of residue (more correctly, of the P atom)\n",
      "    #x, y, z = t.xyz[frame_index, residue._atoms[0].index]\n",
      "    x, y, z = t.xyz[frame_index, atom.index]\n",
      "    \n",
      "    # Get magnitude of distance to the spot center\n",
      "    distance = (x - spotX)**2 + (y - spotY)**2\n",
      "    \n",
      "    # Truncate at 2 sigma\n",
      "    if distance > CUTOFF**2 * w_xy**2:\n",
      "        return 0.0\n",
      "\n",
      "    # Calculate contribution to intensity from an atom, based on the Gaussian\n",
      "    #   profile of the incident beam and the particle's position.\n",
      "    intensity = \\\n",
      "        INTENSITY * np.exp(\n",
      "        -( distance ) # + ((z - spotZ)/k)**2)\n",
      "        / (2 * w_xy**2) )\n",
      "\n",
      "    return intensity"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### `analyze_frame`\n",
      "\n",
      "Analyzes the positions of atoms in a given frame, and updates the detections list with each atom's position."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def analyze_frame(t, frame_index, detections): \n",
      "    \n",
      "    print(\"\\rProcessing frame %d out of %d\" % (frame_index/STEP, len(t)/STEP), end=\"\\r\")\n",
      "\n",
      "    # Iterate through each atom remaining in the topology\n",
      "    for atom in t.topology.atoms:\n",
      "\n",
      "        # Do analysis if atom is in detection volume\n",
      "        if not check_in_detection_volume(t, frame_index, atom):\n",
      "            print(\"Not in detection volume, skipping.\")\n",
      "            continue\n",
      "\n",
      "        detected = generate_detection(t, frame_index, atom)\n",
      "        \n",
      "        detections[atom.index][int(frame_index/STEP)] = detected"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Load trajectory data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Import FCS data from .xtc file. Also specify a .gro file for the system topology.\n",
      "\n",
      "**NB:** A .trr file can be used for better resolution, since an .xtc typically uses some compression. However, a .trr is also much larger."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "#t = md.load(trajectory_file, top=topology_file)\n",
      "t = md.load_trr(trr_file, top=topology_file)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Calculate timestep for data analysis, given the simulation data timestep and current stride."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Timestep for data analysis is %.2f picoseconds (%.2f nanoseconds)\" % (t.timestep * STEP, t.timestep * STEP / 1000))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Reduce atom selection to only phosphorous atoms\n",
      "\n",
      "This is a bit of a simplification, but significantly reduces the amount of atoms to iterate over if we're only considering the phosphorous at the center of the phosphate group. Error from this would be on the order of the bond lengths, so roughly 1.5 angstrom."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(\"Starting with %d atoms\" % t.topology.n_atoms)\n",
      "\n",
      "phosphorous_atoms = [a.index for a in t.topology.atoms if a.element.symbol == 'P']\n",
      "t.atom_slice(phosphorous_atoms, inplace=True)\n",
      "\n",
      "print(\"Reduced to %d phosphorous atoms\" % t.topology.n_atoms)\n",
      "\n",
      "# Reduce to the sampling ratio * number of phosphorous atoms\n",
      "num_sampled = int(t.topology.n_atoms * SAMPLING_RATIO)\n",
      "\n",
      "# Randomly select the sampled atoms\n",
      "sampled = np.random.choice([a.index for a in t.topology.atoms], num_sampled, replace=False)\n",
      "t.atom_slice(sampled, inplace=True)\n",
      "\n",
      "print(\"Reduced to %d \\\"tagged\\\" phosphorous atoms\" % t.topology.n_atoms)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create a list of lists to store detected intensity for each lipid.\n",
      "\n",
      "Need to use something like this list comprehension, rather than `[[]] * len(t.topology.residues)` to deep copy the list elements -- otherwise they'll all be aliases of each other!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "frames = range(0, len(t), STEP)\n",
      "detections = [ [ [] for x in frames ] for x in t.topology.residues ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Data Analysis\n",
      "\n",
      "Iterate through each frame of data in the trajectory file, and generate a detected intensity from each lipid (represented by its p atom)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for frame_index in range(0, len(t), STEP):\n",
      "    analyze_frame(t, frame_index, detections)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Bin lipids in data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_bins = int(np.ceil(t.topology.n_residues/BIN_SIZE))\n",
      "\n",
      "if not t.topology.n_residues%BIN_SIZE == 0:\n",
      "    print(\"Number of residues is not evenly divisible by bin size. Desired size is %d, one bin will contain %d.\" % (BIN_SIZE, t.topology.n_residues%BIN_SIZE) )\n",
      "\n",
      "print(\"Sorting data into %d groups\" % n_bins)\n",
      "\n",
      "binned =  [ [] for x in range(t.topology.n_residues//BIN_SIZE) ]\n",
      "\n",
      "binned_tots, binned_avgs, binned_dI = [], [], []\n",
      "\n",
      "# TODO: May want to use np.random.choice to randomly select the binned lipids, though the choice of lipids to sample is already random\n",
      "# For each group...\n",
      "for g in range(n_bins):\n",
      "    \n",
      "    # Pick the slice of detections that are relevant to it\n",
      "    _detections = [x for x in detections[g*BIN_SIZE:BIN_SIZE*(g+1)]]\n",
      "        \n",
      "    \n",
      "    avg_I = np.mean(_detections, axis=0)\n",
      "    tot_I = np.sum(_detections, axis=0)\n",
      "    \n",
      "    delta_I = [tot_I[x] - avg_I[x] for x in range(len(tot_I))]\n",
      "    \n",
      "    \n",
      "    binned_tots.append(tot_I)\n",
      "    binned_avgs.append(avg_I)\n",
      "    binned_dI.append(delta_I)\n",
      "    \n",
      "binned_tots = np.sum(binned_tots, axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Plotting"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Intensity Traces\n",
      "Plot the intensity traces for the individual lipids, and for the summed intensities."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "################## Plot intensity traces #############################\n",
      "# Plot the intensities of detections associated with each lipid\n",
      "plt.subplot(221)\n",
      "for _data in binned_avgs:\n",
      "    plt.plot(np.arange(0, len(t), 1), _data, marker='o', markersize=.5 ) \n",
      "plt.xlabel(\"Time (ns)\")\n",
      "plt.ylabel(\"Intensity\")\n",
      "plt.title(\"Intensity Trace\")\n",
      "\n",
      "# Plot sum of intensities (i.e. what a detector would see)\n",
      "plt.subplot(222)\n",
      "plt.plot(np.arange(0, len(t), 1), binned_tots, marker='None', markersize=.5 ) \n",
      "# summed_data = np.sum(intensities, axis=0)\n",
      "# #plt.plot(np.arange(0,len(summed_data), 1), summed_data, marker = 'o', markersize=.1, )\n",
      "# plt.plot(np.arange(0,len(binned), 1), [x[1] for x in binned], marker = 'o', markersize=.1, )\n",
      "plt.xlabel(\"Time (ns)\")\n",
      "plt.ylabel(\"Intensity\")\n",
      "plt.title(\"Summed Intensity Trace\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Autocorrelations\n",
      "Plot the autocorrelation functions for the individual lipids tracked, and for the summed intensities of all of them."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Don't set the max lag to greater than the number of datapoints..\n",
      "max_lag = min([100 * int(tauD), (len(t) -1) * STEP])\n",
      "\n",
      "tauD = w_xy**2 / (4*D) * 2.5\n",
      "\n",
      "# Individual data\n",
      "plt.subplot(221)\n",
      "plt.xscale('log')\n",
      "\n",
      "for _data in binned_avgs:\n",
      "    plt.acorr(_data, maxlags=max_lag, usevlines=False, linestyle='-', marker=\"None\", normed=True)\n",
      "\n",
      "plt.xlabel(\"Time lag (ns)\")\n",
      "plt.title(\"Normalized Autocorrelation\")\n",
      "\n",
      "# Plot model curve\n",
      "_x = np.linspace(0,len(t), 5000)\n",
      "_G =(1 + _x / tauD)**(-1)\n",
      "plt.plot(_x, _G, linestyle='--', linewidth=4)\n",
      "    \n",
      "# Plot tau_D, diffusion time\n",
      "plt.axvline(tauD)\n",
      "plt.xticks(list(plt.xticks()[0]) + [tauD], list(plt.xticks()[0]) + ['tau_D'])\n",
      "plt.xlim([10,max_lag])\n",
      "\n",
      "\n",
      "# Summed data\n",
      "plt.subplot(222)\n",
      "plt.xscale('log')\n",
      "\n",
      "plt.acorr(binned_tots, maxlags=max_lag, usevlines=False, linestyle='-', marker=\"None\", normed=True)\n",
      "\n",
      "\n",
      "# Plot model curve\n",
      "_x = np.linspace(0,len(t), 5000)\n",
      "_G = (1 + _x / tauD)**(-1)\n",
      "plt.plot(_x, _G, linestyle='--', linewidth=4)\n",
      "\n",
      "plt.xlabel(\"Time lag (ns)\")\n",
      "plt.title(\"Normalized Autocorrelation\")\n",
      "    \n",
      "# Plot tau_D, diffusion time\n",
      "plt.axvline(tauD)\n",
      "plt.xticks(list(plt.xticks()[0]) + [tauD], list(plt.xticks()[0]) + ['tau_D'])\n",
      "plt.xlim([10,max_lag])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Manually generate autocorrelation data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Manually autocorrelate the data, without relying on plt.acorr -- produces the exact same curve as plt.acorr with normed=False\n",
      "plt.subplot(221)\n",
      "plt.xscale('log')\n",
      "autocorrelated = np.correlate(binned_tots, binned_tots, mode='full')\n",
      "autocorrelated = autocorrelated[(autocorrelated.size-1)//2 :]\n",
      "plt.plot(autocorrelated, linestyle='-')\n",
      "\n",
      "_x = np.linspace(0,len(t)*2, 5000)\n",
      "_G = 1/.000000445 * (1 + _x / tauD)**(-1)\n",
      "plt.plot(_x, _G, linestyle='-')\n",
      "plt.xlim([10,len(t)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(t)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}